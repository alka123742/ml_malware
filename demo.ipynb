{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv('./data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__arm_nr_cacheflush</th>\n",
       "      <th>__arm_nr_set_tls</th>\n",
       "      <th>_llseek</th>\n",
       "      <th>_newselect</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>bind</th>\n",
       "      <th>brk</th>\n",
       "      <th>capset</th>\n",
       "      <th>chdir</th>\n",
       "      <th>...</th>\n",
       "      <th>ugetrlimit</th>\n",
       "      <th>umask</th>\n",
       "      <th>uname</th>\n",
       "      <th>unlink</th>\n",
       "      <th>utimes</th>\n",
       "      <th>vfork</th>\n",
       "      <th>wait4</th>\n",
       "      <th>write</th>\n",
       "      <th>writev</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1590</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2840</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>987</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11593</th>\n",
       "      <td>3120</td>\n",
       "      <td>61</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>772</td>\n",
       "      <td>12</td>\n",
       "      <td>667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2760</td>\n",
       "      <td>236</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11594</th>\n",
       "      <td>39000</td>\n",
       "      <td>70</td>\n",
       "      <td>66</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>8</td>\n",
       "      <td>995</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4420</td>\n",
       "      <td>295</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11595</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>112</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11596</th>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>115</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>525</td>\n",
       "      <td>23</td>\n",
       "      <td>349</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1700</td>\n",
       "      <td>774</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11597</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>204</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>20</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3100</td>\n",
       "      <td>186</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11598 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       __arm_nr_cacheflush  __arm_nr_set_tls  _llseek  _newselect  accept  \\\n",
       "0                        0                14        6           0       0   \n",
       "1                     1590                42        6           0       0   \n",
       "2                        0                23        6           0       0   \n",
       "3                        0                27        6           0       0   \n",
       "4                        0                18        6           0       0   \n",
       "...                    ...               ...      ...         ...     ...   \n",
       "11593                 3120                61       12          34       0   \n",
       "11594                39000                70       66          20       0   \n",
       "11595                    0                21      112           9       0   \n",
       "11596                    0                90      115          75       0   \n",
       "11597                    0                47      204          26       0   \n",
       "\n",
       "       access  bind   brk  capset  chdir  ...  ugetrlimit  umask  uname  \\\n",
       "0          11     3    21       1      0  ...           0      0      1   \n",
       "1          47     2  1430       1      0  ...           2      0      1   \n",
       "2          40     9    89       1      0  ...           0      0      1   \n",
       "3          60     1   242       1      0  ...           0      0      1   \n",
       "4          26     5    59       1      0  ...           0      0      1   \n",
       "...       ...   ...   ...     ...    ...  ...         ...    ...    ...   \n",
       "11593     772    12   667       1      0  ...           3      0      2   \n",
       "11594     147     8   995       1      0  ...           3      0      1   \n",
       "11595      97     1   194       1      0  ...           0      0      1   \n",
       "11596     525    23   349       1      0  ...           1      0      1   \n",
       "11597     172    20   270       1      0  ...           1      0      1   \n",
       "\n",
       "       unlink  utimes  vfork  wait4  write  writev  Class  \n",
       "0           0       0      0      0     37      10      1  \n",
       "1           4       0      0      0   2840      46      1  \n",
       "2           2       0      0      0    111      20      1  \n",
       "3           2       0      0      0    987     197      1  \n",
       "4           0       0      0      0     98      25      1  \n",
       "...       ...     ...    ...    ...    ...     ...    ...  \n",
       "11593      21       0      0      0   2760     236      5  \n",
       "11594      21       0      0      1   4420     295      5  \n",
       "11595       9       0      0      0    241      67      5  \n",
       "11596      56       0      0      0   1700     774      5  \n",
       "11597      13       0      0      0   3100     186      5  \n",
       "\n",
       "[11598 rows x 140 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__arm_nr_cacheflush</th>\n",
       "      <th>__arm_nr_set_tls</th>\n",
       "      <th>_llseek</th>\n",
       "      <th>_newselect</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>bind</th>\n",
       "      <th>brk</th>\n",
       "      <th>capset</th>\n",
       "      <th>chdir</th>\n",
       "      <th>...</th>\n",
       "      <th>ugetrlimit</th>\n",
       "      <th>umask</th>\n",
       "      <th>uname</th>\n",
       "      <th>unlink</th>\n",
       "      <th>utimes</th>\n",
       "      <th>vfork</th>\n",
       "      <th>wait4</th>\n",
       "      <th>write</th>\n",
       "      <th>writev</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11598.000000</td>\n",
       "      <td>11598.000000</td>\n",
       "      <td>11598.000000</td>\n",
       "      <td>11598.000000</td>\n",
       "      <td>11598.000000</td>\n",
       "      <td>11598.000000</td>\n",
       "      <td>11598.000000</td>\n",
       "      <td>11598.000000</td>\n",
       "      <td>11598.000000</td>\n",
       "      <td>11598.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11598.000000</td>\n",
       "      <td>11598.000000</td>\n",
       "      <td>11598.000000</td>\n",
       "      <td>11598.000000</td>\n",
       "      <td>11598.000000</td>\n",
       "      <td>11598.000000</td>\n",
       "      <td>11598.000000</td>\n",
       "      <td>11598.000000</td>\n",
       "      <td>1.159800e+04</td>\n",
       "      <td>11598.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1082.921797</td>\n",
       "      <td>30.567167</td>\n",
       "      <td>213.422573</td>\n",
       "      <td>53.544835</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>304.551647</td>\n",
       "      <td>6.897310</td>\n",
       "      <td>172.311002</td>\n",
       "      <td>0.982928</td>\n",
       "      <td>0.075616</td>\n",
       "      <td>...</td>\n",
       "      <td>1.470081</td>\n",
       "      <td>0.023625</td>\n",
       "      <td>1.068891</td>\n",
       "      <td>8.636834</td>\n",
       "      <td>0.093292</td>\n",
       "      <td>2.232454</td>\n",
       "      <td>6.451285</td>\n",
       "      <td>1071.327729</td>\n",
       "      <td>1.039400e+03</td>\n",
       "      <td>3.131919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4397.856096</td>\n",
       "      <td>33.926628</td>\n",
       "      <td>3031.751994</td>\n",
       "      <td>919.705798</td>\n",
       "      <td>0.066905</td>\n",
       "      <td>1621.502959</td>\n",
       "      <td>27.191303</td>\n",
       "      <td>280.987609</td>\n",
       "      <td>0.129545</td>\n",
       "      <td>2.490141</td>\n",
       "      <td>...</td>\n",
       "      <td>3.685197</td>\n",
       "      <td>1.581385</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>21.649011</td>\n",
       "      <td>1.808335</td>\n",
       "      <td>15.691146</td>\n",
       "      <td>163.995008</td>\n",
       "      <td>6150.977874</td>\n",
       "      <td>1.711596e+04</td>\n",
       "      <td>1.197716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1140.000000</td>\n",
       "      <td>1.440000e+02</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>117000.000000</td>\n",
       "      <td>1330.000000</td>\n",
       "      <td>65800.000000</td>\n",
       "      <td>55700.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>16400.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>7700.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>17400.000000</td>\n",
       "      <td>490000.000000</td>\n",
       "      <td>1.300000e+06</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       __arm_nr_cacheflush  __arm_nr_set_tls       _llseek    _newselect  \\\n",
       "count         11598.000000      11598.000000  11598.000000  11598.000000   \n",
       "mean           1082.921797         30.567167    213.422573     53.544835   \n",
       "std            4397.856096         33.926628   3031.751994    919.705798   \n",
       "min               0.000000          0.000000      0.000000      0.000000   \n",
       "25%               0.000000         10.000000      6.000000      0.000000   \n",
       "50%               0.000000         17.000000      6.000000      0.000000   \n",
       "75%               0.000000         39.000000     34.000000      0.000000   \n",
       "max          117000.000000       1330.000000  65800.000000  55700.000000   \n",
       "\n",
       "             accept        access          bind           brk        capset  \\\n",
       "count  11598.000000  11598.000000  11598.000000  11598.000000  11598.000000   \n",
       "mean       0.002759    304.551647      6.897310    172.311002      0.982928   \n",
       "std        0.066905   1621.502959     27.191303    280.987609      0.129545   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      8.000000      0.000000     31.000000      1.000000   \n",
       "50%        0.000000     22.000000      1.000000     73.000000      1.000000   \n",
       "75%        0.000000     96.000000      5.000000    217.000000      1.000000   \n",
       "max        3.000000  16400.000000   1490.000000   7700.000000      1.000000   \n",
       "\n",
       "              chdir  ...    ugetrlimit         umask         uname  \\\n",
       "count  11598.000000  ...  11598.000000  11598.000000  11598.000000   \n",
       "mean       0.075616  ...      1.470081      0.023625      1.068891   \n",
       "std        2.490141  ...      3.685197      1.581385      0.520508   \n",
       "min        0.000000  ...      0.000000      0.000000      0.000000   \n",
       "25%        0.000000  ...      0.000000      0.000000      1.000000   \n",
       "50%        0.000000  ...      0.000000      0.000000      1.000000   \n",
       "75%        0.000000  ...      2.000000      0.000000      1.000000   \n",
       "max      216.000000  ...     90.000000    164.000000     23.000000   \n",
       "\n",
       "             unlink        utimes         vfork         wait4          write  \\\n",
       "count  11598.000000  11598.000000  11598.000000  11598.000000   11598.000000   \n",
       "mean       8.636834      0.093292      2.232454      6.451285    1071.327729   \n",
       "std       21.649011      1.808335     15.691146    163.995008    6150.977874   \n",
       "min        0.000000      0.000000      0.000000      0.000000       0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      71.000000   \n",
       "50%        2.000000      0.000000      0.000000      0.000000     256.000000   \n",
       "75%        8.000000      0.000000      0.000000      0.000000    1140.000000   \n",
       "max     1200.000000    113.000000    117.000000  17400.000000  490000.000000   \n",
       "\n",
       "             writev         Class  \n",
       "count  1.159800e+04  11598.000000  \n",
       "mean   1.039400e+03      3.131919  \n",
       "std    1.711596e+04      1.197716  \n",
       "min    0.000000e+00      1.000000  \n",
       "25%    1.200000e+01      2.000000  \n",
       "50%    4.400000e+01      3.000000  \n",
       "75%    1.440000e+02      4.000000  \n",
       "max    1.300000e+06      5.000000  \n",
       "\n",
       "[8 rows x 140 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total missings 0\n"
     ]
    }
   ],
   "source": [
    "print(\"total missings\",sum(df.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Classes')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes,count = np.unique(df['Class'],return_counts=True)\n",
    "plt.bar(classes, count)\n",
    "plt.title(\"Class Balance\")\n",
    "plt.xlabel(\"Classes\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do upsampling(oversampling) for the minority class.\n",
    "SMOTE is capable of generating synthetic data for minority class. And, Tomek Links is able to remove the data that are identified as Tomek links from the majority class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Class'], axis=1)\n",
    "y = df['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3659332061.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [22]\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install imbalanced-learn\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "# Define SMOTE-Tomek Links\n",
    "resample=SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))\n",
    "X, y = resample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class after balanced: Counter({2: 3904, 3: 3904, 4: 3904, 5: 3904, 1: 3890})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(f\"Class after balanced: {Counter(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Classes')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l,z = np.unique(y,return_counts=True)\n",
    "plt.bar(l,z)\n",
    "plt.title(\"Class After Resampling\")\n",
    "plt.xlabel(\"Classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_type = ['Adware', 'Banking', 'SMS malware', 'Riskware', 'Benign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "transformed = ohe.fit_transform(df[['Class']])\n",
    "print(transformed.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11598, 140)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:139]\n",
    "y = df.iloc[:,-5:]\n",
    "y_nohe = df['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# the first row has the Class without one-hot encoding, and the second row is the one after one-hot encoding\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y_nohe,test_size = 0.2,shuffle=True)\n",
    "X_train_1,X_test_1,y_train_1,y_test_1 = train_test_split(X,y,test_size = 0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X_train)    # Only the training data are used to fit the scaler transformation,\n",
    "X_train_scaled = scaler.transform(X_train) \n",
    "X_test_scaled = scaler.transform(X_test)  # then the scaler is used to transform the test input data.\n",
    "scaler.fit(X_train_1)    # Only the training data are used to fit the scaler transformation,\n",
    "X_train_1_scaled = scaler.transform(X_train_1) \n",
    "X_test_1_scaled = scaler.transform(X_test_1)  # then the scaler is used to transform the test input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (9278, 139) Y_train (9278,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train\",X_train.shape,\"Y_train\",y_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (RF)\n",
    "> The prerequisites for random forest to perform well are:\n",
    "\n",
    "    1. There needs to be some actual signal in our features so that models built using those features do better than random guessing.\n",
    "    2. The predictions (and therefore the errors) made by the individual trees need to have low correlations with each other.\n",
    "\n",
    "Since that this dataset generally meets these two prerequisites, the accuracy is quite excellent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9267241379310345\n"
     ]
    }
   ],
   "source": [
    "# make prediction \n",
    "from sklearn.metrics import accuracy_score\n",
    "rf_preds = rf_classifier.predict(X_test_scaled) \n",
    "# check performance\n",
    "res = accuracy_score(rf_preds,y_test)\n",
    "print('Accuracy score: ', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.713 total time=  10.1s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.708 total time=   9.7s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.720 total time=   9.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.711 total time=   8.3s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.736 total time=   7.9s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.687 total time=   7.9s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.684 total time=   8.3s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.662 total time=   7.5s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.686 total time=   7.4s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.700 total time=   8.2s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.577 total time=   8.2s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.560 total time=   7.7s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.570 total time=   8.1s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.577 total time=   7.8s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.583 total time=   8.2s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.503 total time=  10.4s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.490 total time=   9.7s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.494 total time=   9.7s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.494 total time=  10.9s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.496 total time=  10.6s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.387 total time=  12.9s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.377 total time=  13.1s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.377 total time=  12.6s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.389 total time=  12.2s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.381 total time=  11.7s\n",
      "[CV 1/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.568 total time=   9.2s\n",
      "[CV 2/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.554 total time=   9.6s\n",
      "[CV 3/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.560 total time=   9.6s\n",
      "[CV 4/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.562 total time=   9.3s\n",
      "[CV 5/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.570 total time=   9.3s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.827 total time=   7.1s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.837 total time=   6.6s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.837 total time=   6.8s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.833 total time=   6.9s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.849 total time=   7.2s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.823 total time=   6.4s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.809 total time=   6.1s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.815 total time=   6.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.792 total time=   6.5s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.823 total time=   6.3s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.719 total time=   7.3s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.707 total time=   7.6s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.710 total time=   7.5s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.709 total time=   6.4s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.722 total time=   7.2s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.584 total time=   9.3s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.574 total time=  11.1s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.580 total time=   8.2s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.571 total time=   9.7s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.581 total time=   9.4s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.509 total time=  13.7s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.489 total time=  12.1s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.492 total time=  10.8s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.492 total time=  12.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.498 total time=  11.6s\n",
      "[CV 1/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.706 total time=   7.7s\n",
      "[CV 2/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.695 total time=   7.1s\n",
      "[CV 3/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.696 total time=   6.8s\n",
      "[CV 4/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.701 total time=   7.9s\n",
      "[CV 5/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.701 total time=   7.5s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.852 total time=   7.3s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.860 total time=   7.2s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.860 total time=   6.2s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.865 total time=   7.4s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.868 total time=   7.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.863 total time=   5.1s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.866 total time=   5.2s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.869 total time=   5.4s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.854 total time=   6.3s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.875 total time=   7.3s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.797 total time=   6.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.808 total time=   6.9s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.789 total time=   7.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.791 total time=   5.9s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.822 total time=   6.7s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.702 total time=   7.5s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.680 total time=   7.8s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.695 total time=   8.9s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.694 total time=   9.2s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.706 total time=   8.8s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.582 total time=  10.1s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.568 total time=  10.8s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.575 total time=   9.5s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.566 total time=   9.7s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.570 total time=  10.6s\n",
      "[CV 1/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.793 total time=   7.4s\n",
      "[CV 2/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.782 total time=   6.1s\n",
      "[CV 3/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.776 total time=   7.4s\n",
      "[CV 4/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.764 total time=   7.4s\n",
      "[CV 5/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.799 total time=   6.3s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.852 total time=   7.0s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.869 total time=   6.7s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.865 total time=   6.8s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.866 total time=   6.7s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.877 total time=   9.3s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.878 total time=   3.9s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.883 total time=   3.6s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.889 total time=   4.1s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.879 total time=   4.6s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.888 total time=   4.0s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.858 total time=   4.4s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.870 total time=   4.5s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.860 total time=   4.8s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.850 total time=   4.9s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.873 total time=   4.3s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.780 total time=   5.7s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.772 total time=   5.8s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.768 total time=   5.9s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.764 total time=   6.1s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.788 total time=   6.3s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.679 total time=   7.7s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.668 total time=   7.5s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.673 total time=   7.9s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.683 total time=   6.8s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.696 total time=   7.2s\n",
      "[CV 1/5] END .....C=100, gamma=auto, kernel=rbf;, score=0.850 total time=   4.1s\n",
      "[CV 2/5] END .....C=100, gamma=auto, kernel=rbf;, score=0.852 total time=   4.6s\n",
      "[CV 3/5] END .....C=100, gamma=auto, kernel=rbf;, score=0.851 total time=   4.6s\n",
      "[CV 4/5] END .....C=100, gamma=auto, kernel=rbf;, score=0.836 total time=   5.1s\n",
      "[CV 5/5] END .....C=100, gamma=auto, kernel=rbf;, score=0.867 total time=   4.7s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.855 total time=   7.3s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.867 total time=   6.8s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.868 total time=   8.1s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.866 total time=   8.2s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.879 total time=   8.4s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.887 total time=   5.3s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.890 total time=   4.2s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.895 total time=   4.4s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.875 total time=   4.2s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.893 total time=   3.9s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.876 total time=   4.0s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.886 total time=   4.6s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.882 total time=   4.0s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.885 total time=   3.6s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.891 total time=   4.3s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.835 total time=   5.3s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.834 total time=   5.3s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.818 total time=   5.3s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.830 total time=   5.4s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.861 total time=   5.5s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.762 total time=   6.1s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.767 total time=   6.4s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.753 total time=   6.2s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.753 total time=   6.8s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.778 total time=  10.8s\n",
      "[CV 1/5] END ....C=1000, gamma=auto, kernel=rbf;, score=0.872 total time=   8.3s\n",
      "[CV 2/5] END ....C=1000, gamma=auto, kernel=rbf;, score=0.880 total time=   8.5s\n",
      "[CV 3/5] END ....C=1000, gamma=auto, kernel=rbf;, score=0.877 total time=   8.8s\n",
      "[CV 4/5] END ....C=1000, gamma=auto, kernel=rbf;, score=0.876 total time=   7.4s\n",
      "[CV 5/5] END ....C=1000, gamma=auto, kernel=rbf;, score=0.886 total time=   8.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001, 'auto'],\n",
       "                         'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining parameter range \n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "            'gamma': [1, 0.1, 0.01, 0.001, 0.0001, 'auto'], \n",
    "            'kernel': ['rbf']} \n",
    "\n",
    "rbf_grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n",
    "\n",
    "# fitting the model for grid search \n",
    "rbf_grid.fit(X_train_scaled, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.8801724137931034\n"
     ]
    }
   ],
   "source": [
    "print(rbf_grid.best_params_) \n",
    "rbf_predictions = rbf_grid.predict(X_test_scaled) \n",
    "\n",
    "# print classification report\n",
    "print(accuracy_score(y_test, rbf_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 (RBF Kernel):  88.06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "rbf_f1 = f1_score(y_test, rbf_predictions, average='weighted')\n",
    "print('F1 (RBF Kernel): ', \"%.2f\" % (rbf_f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation accuracy scores: [0.8674569  0.85452586 0.86637931 0.84159483 0.87068966 0.8512931\n",
      " 0.84590517 0.8512931  0.85652643 0.86084142]\n",
      "Baseline: 85.67% (0.91%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "#estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(knn, X=X_train_scaled, y=y_train, cv=kfold)\n",
    "print('Cross Validation accuracy scores: %s' % results)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "error_rate = []\n",
    "\n",
    "for i in range(1,30):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train_scaled,y_train)\n",
    "    pred_i = knn.predict(X_test_scaled)\n",
    "    error_rate.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,30),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arama\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\arama\\Desktop\\ml proj summer\\demo.ipynb Cell 33\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arama/Desktop/ml%20proj%20summer/demo.ipynb#X45sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m knn\u001b[39m.\u001b[39mfit(X_train_scaled,y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arama/Desktop/ml%20proj%20summer/demo.ipynb#X45sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pred \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39mpredict(X_test_scaled)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/arama/Desktop/ml%20proj%20summer/demo.ipynb#X45sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m cm \u001b[39m=\u001b[39m confusion_matrix(y_test, pred)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arama/Desktop/ml%20proj%20summer/demo.ipynb#X45sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m cm_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(cm,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/arama/Desktop/ml%20proj%20summer/demo.ipynb#X45sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                      index \u001b[39m=\u001b[39m class_type, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arama/Desktop/ml%20proj%20summer/demo.ipynb#X45sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                      columns \u001b[39m=\u001b[39m class_type)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/arama/Desktop/ml%20proj%20summer/demo.ipynb#X45sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mWITH K=1\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn.fit(X_train_scaled,y_train)\n",
    "pred = knn.predict(X_test_scaled)\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = class_type, \n",
    "                     columns = class_type)\n",
    "print('WITH K=1')\n",
    "print('\\n')\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_df, annot=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.show()\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
